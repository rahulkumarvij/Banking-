{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880b74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647ca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv(\"train_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0bd5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Split the data into numerical and categorical features\n",
    "num_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_features.remove(\"isFraud\")\n",
    "cat_features = df.select_dtypes(include=[object]).columns.tolist()\n",
    "print(1)\n",
    "# Impute missing values for numerical features with the mean\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df[num_features] = num_imputer.fit_transform(df[num_features])\n",
    "print(2)\n",
    "# Impute missing values for categorical features with the most frequent value\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_features] = cat_imputer.fit_transform(df[cat_features])\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1f16ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>7.372311e+06</td>\n",
       "      <td>135.027176</td>\n",
       "      <td>9898.734658</td>\n",
       "      <td>362.555488</td>\n",
       "      <td>153.194925</td>\n",
       "      <td>199.278897</td>\n",
       "      <td>290.733794</td>\n",
       "      <td>86.800630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>721.741883</td>\n",
       "      <td>1375.783644</td>\n",
       "      <td>1014.622782</td>\n",
       "      <td>9.807015</td>\n",
       "      <td>59.164550</td>\n",
       "      <td>28.530903</td>\n",
       "      <td>55.352422</td>\n",
       "      <td>151.160542</td>\n",
       "      <td>100.700882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.704744e+05</td>\n",
       "      <td>0.183755</td>\n",
       "      <td>4.617224e+06</td>\n",
       "      <td>239.162522</td>\n",
       "      <td>4901.170153</td>\n",
       "      <td>156.595240</td>\n",
       "      <td>11.321413</td>\n",
       "      <td>41.095455</td>\n",
       "      <td>95.914128</td>\n",
       "      <td>2.536525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.765559</td>\n",
       "      <td>2321.688741</td>\n",
       "      <td>4170.926347</td>\n",
       "      <td>2970.898706</td>\n",
       "      <td>91.064804</td>\n",
       "      <td>144.751912</td>\n",
       "      <td>102.534859</td>\n",
       "      <td>249.632064</td>\n",
       "      <td>408.917095</td>\n",
       "      <td>304.324367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.987000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.134635e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.027058e+06</td>\n",
       "      <td>43.321000</td>\n",
       "      <td>6019.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>721.741883</td>\n",
       "      <td>1375.783644</td>\n",
       "      <td>1014.622782</td>\n",
       "      <td>9.807015</td>\n",
       "      <td>59.164550</td>\n",
       "      <td>28.530903</td>\n",
       "      <td>55.352422</td>\n",
       "      <td>151.160542</td>\n",
       "      <td>100.700882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.306528e+06</td>\n",
       "      <td>68.769000</td>\n",
       "      <td>9678.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>290.733794</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>721.741883</td>\n",
       "      <td>1375.783644</td>\n",
       "      <td>1014.622782</td>\n",
       "      <td>9.807015</td>\n",
       "      <td>59.164550</td>\n",
       "      <td>28.530903</td>\n",
       "      <td>55.352422</td>\n",
       "      <td>151.160542</td>\n",
       "      <td>100.700882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.429904e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124662e+07</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>14184.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>721.741883</td>\n",
       "      <td>1375.783644</td>\n",
       "      <td>1014.622782</td>\n",
       "      <td>9.807015</td>\n",
       "      <td>59.164550</td>\n",
       "      <td>28.530903</td>\n",
       "      <td>55.352422</td>\n",
       "      <td>151.160542</td>\n",
       "      <td>100.700882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.577539e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581113e+07</td>\n",
       "      <td>31937.391000</td>\n",
       "      <td>18396.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
       "count   5.905400e+05  590540.000000   5.905400e+05   590540.000000   \n",
       "mean    3.282270e+06       0.034990   7.372311e+06      135.027176   \n",
       "std     1.704744e+05       0.183755   4.617224e+06      239.162522   \n",
       "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
       "25%     3.134635e+06       0.000000   3.027058e+06       43.321000   \n",
       "50%     3.282270e+06       0.000000   7.306528e+06       68.769000   \n",
       "75%     3.429904e+06       0.000000   1.124662e+07      125.000000   \n",
       "max     3.577539e+06       1.000000   1.581113e+07    31937.391000   \n",
       "\n",
       "               card1          card2          card3          card5  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean     9898.734658     362.555488     153.194925     199.278897   \n",
       "std      4901.170153     156.595240      11.321413      41.095455   \n",
       "min      1000.000000     100.000000     100.000000     100.000000   \n",
       "25%      6019.000000     215.000000     150.000000     166.000000   \n",
       "50%      9678.000000     361.000000     150.000000     226.000000   \n",
       "75%     14184.000000     512.000000     150.000000     226.000000   \n",
       "max     18396.000000     600.000000     231.000000     237.000000   \n",
       "\n",
       "               addr1          addr2  ...           V330           V331  \\\n",
       "count  590540.000000  590540.000000  ...  590540.000000  590540.000000   \n",
       "mean      290.733794      86.800630  ...       0.775874     721.741883   \n",
       "std        95.914128       2.536525  ...       1.765559    2321.688741   \n",
       "min       100.000000      10.000000  ...       0.000000       0.000000   \n",
       "25%       205.000000      87.000000  ...       0.775874     721.741883   \n",
       "50%       290.733794      87.000000  ...       0.775874     721.741883   \n",
       "75%       327.000000      87.000000  ...       0.775874     721.741883   \n",
       "max       540.000000     102.000000  ...      55.000000  160000.000000   \n",
       "\n",
       "                V332           V333           V334           V335  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean     1375.783644    1014.622782       9.807015      59.164550   \n",
       "std      4170.926347    2970.898706      91.064804     144.751912   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%      1375.783644    1014.622782       9.807015      59.164550   \n",
       "50%      1375.783644    1014.622782       9.807015      59.164550   \n",
       "75%      1375.783644    1014.622782       9.807015      59.164550   \n",
       "max    160000.000000  160000.000000   55125.000000   55125.000000   \n",
       "\n",
       "                V336           V337           V338           V339  \n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000  \n",
       "mean       28.530903      55.352422     151.160542     100.700882  \n",
       "std       102.534859     249.632064     408.917095     304.324367  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%        28.530903      55.352422     151.160542     100.700882  \n",
       "50%        28.530903      55.352422     151.160542     100.700882  \n",
       "75%        28.530903      55.352422     151.160542     100.700882  \n",
       "max     55125.000000  104060.000000  104060.000000  104060.000000  \n",
       "\n",
       "[8 rows x 380 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fe5f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 394)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb61af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[num_features])\n",
    "\n",
    "# Preprocess the categorical features\n",
    "encoder = OneHotEncoder()\n",
    "X_cat = encoder.fit_transform(df[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb990b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the numerical and categorical features\n",
    "X = pd.concat([pd.DataFrame(X_num), pd.DataFrame(X_cat.toarray())], axis=1)\n",
    "y = df[\"isFraud\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "classifier = LogisticRegression(max_iter=100)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c594bc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 530)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2dbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class labels for the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03eb6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99    114056\n",
      "           1       0.81      0.26      0.39      4052\n",
      "\n",
      "    accuracy                           0.97    118108\n",
      "   macro avg       0.89      0.63      0.69    118108\n",
      "weighted avg       0.97      0.97      0.97    118108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
